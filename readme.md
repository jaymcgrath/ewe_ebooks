<h1>Ewe Ebooks</h1>

A Django based admin for creating, configuring, and managing Twitter mashup bots.

<h2> Overview </h2>
By creating an easy to use front end for creation and maintenance of Twitter bots, Ewe Ebooks brings the horse ebooks experience to everyone.  Users can upload their own source material or choose twitter accounts as sources. Then, using a simple user interface, users can easily configure the sources, frequency, and algorithms used to combine their content, then watch as it is automatically posted to twitter on their behalf.

<h2> Specific Functionality </h2>
<h3>Main management page:</h3>
<li>Tabular list of bots configured by this user. Fields are bot_name, last_post_time, content_sources, truncated last_post, and link to individual bot management page.


<h3>Individual bot management page:</h3>
Django form page with the following elements:
<ul>
<li> Generate a tweet button (user can press to generate sample content, shows a dummy tweet with avatar, etc. Used to play with settings)
<li> Twitter API Elements
<li> Tabular list of toggleable sources used to seed this bot. User can turn source inclusion on and off
<li> Link to add a new corpus
<li> Content generation method controls:N-gram length. chain on stopword or shared non-stopword. Shortest tweet length.  Longest tweet length. Autogen hashtag?</ul>

<h3> Corpora Mangement Page</h3>
Tabular list of current corpora configured by the user, with the fields: corpus_name, total_words, total_sentences, and link to edit/deleted corpus.

At top of page, "add source" button and dropdown select for user-generated source or twitter account. If twitter is selected,  a textbox with the "Twitter Screen Name" and an add button will appear.




<h2> Technical Components </h2>
<ul>
<li> Django and postgreSQL based back-end for managing user accounts, bot objects and source material corpora.
<li> Python NLTK-based sentence, word, and N-gram tokenizing.
<li> Uses tweepy Twitter API wrapper for posting bot tweets and seeding user based corpora
<li>  Front-end made with bootstrap css, javascript, ajax, jquery and jqueryUI.
</ul>

<h2> Schedule </h2>
<h4> Week 1</h4>
Creation and testing of business algorithms. Study into NLTK and markov chain bots. Configurable features will be brainstormed and built out from here. Getting started on this early will help me prioritize the rest of the project, and this tough and crucial functionality drives the rest of the project.

<h4> Week 2</h4> Continue tweaking core bot functionality. Start Django project and get database schema into place.


<h2>Models to Create:</h2>
<ul>
<li>Bot -
Fields: Name/access_token/access_frequency/frequency
<li>Corpus - lots of serialized elements to store (possibly a file db for these?)
<li>Tweet - store a log of content generated by each bot
<li>User - tacked on at the end, eventual necessity but not required for demo
</ul>

<h2> Apps </h2>

<h2> Mashup Algorithms </h2>
_Mouse Join_ - method used by
[Mouse Reeve](https://github.com/mouse-reeve/) on [new facts bot](https://twitter.com/brand_new_facts)
uses nltk.pos_tag and pivots on verb tag.

Common clause pivot

<h2> Endpoints </h2>

<h2> Future Features </h2>

<h2> Research Dump </h2>
Good way to store NLTK tokens after parsing?
Dataset module:

https://dataset.readthedocs.io/en/latest/
